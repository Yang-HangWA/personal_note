# Summary of malware classification

* [malware Detection by Eating a Whole exe](https://arxiv.org/pdf/1710.09435.pdf)

### 神经网络malconv
* `挑战`：与其他任务相比，深度学习在恶意软件识别领域还面临着一些挑战和不同之处。对于Portable Executable（PE）恶意软件，这些挑战包括：

    - 将每个字节作为输入序列中的一个单元来处理的话，就意味着我们需要处理时间步长为200万个左右的序列分类问题。据我们所知，这远远超过了之前所有基于神经网络的序列分类器的输入的长度。
    - 恶意软件中的字节包含的信息具有多态性。上下文中的任何特定字节既可以表示为人类可读的文本，也可以表示为二进制代码或任意对象（如图像等）。此外，其中的某些内容可能是经过加密处理的，这样的话，它们对神经网络来说基本上就是随机的。在函数级别上面，二进制的内容可以任意重新排列，但由于函数调用和跳转指令的存在，所以这些函数之间必定存在复杂的空间关系。

* `为什么要选用浅层神经网络`: 因为PE文件的大小限制了训练的batch size，如果模型过于复杂，则在用GPU训练时，需要更多的显存资源。对于恶意程序检测问题，数据预处理是核心部分，输入的数据是否拥有更好的特征表现直接
决定了模型最后的表现，所以并不一定需要特别深的网络来表现程序的特征。

* `方法优点`：
    - 本方法引入了一种人工神经网络，经过适当的训练之后，只需要输入Windows的可执行文件的原始字节序列，它就能区分该文件是良性的，还是恶意的。这种方法的优点如下所示：

    - 不需要手工构建特征或编译器方面的知识。这意味着训练好的模型对于恶意软件的变种具有普适性和鲁棒性。
    - 计算的复杂度与序列长度（二进制文件大小）呈线性关系，这意味着推断是快速的，所以能够用于大型的文件。
    - 能够从二进制文件中找出对于取证分析来说非常重要的代码段。
    - 这种方法也适用于新出现的文件格式、编译器和指令集架构：只需提供相应的训练数据即可。
* `网络核心解决问题及思想`：
   - 计算量和内存用量能够根据序列长度而高效地扩展
   - 在检查整个文件的时候能同时考虑到本地和全局上下文
   - 在分析标记为恶意软件的时候能够提供更好的解释能力
<br>

### malware
  - https://devblogs.nvidia.com/malware-detection-neural-networks/

  - 

  * lief安装bug解决
    - [Anaconda libstdc++.so.6: version `GLIBCXX_3.4.20' not found](https://stackoverflow.com/questions/48453497/anaconda-libstdc-so-6-version-glibcxx-3-4-20-not-found)
    - https://github.com/lief-project/LIEF/releases
    - https://stackoverflow.com/questions/48453497/anaconda-libstdc-so-6-version-glibcxx-3-4-20-not-found
    - conda install libgcc=5.2.0


### 问题总结
- 1.特征选取：
    - 反编译包：pefile、lief、IDA通过反编译包获取PE文件的一些头部信息和Section信息，统计一些反编译之后某些Section中字段出现的频率和出现的顺序信息等。主要和公司相关内核开发人员沟通确定，然后进行试验看效果如何。
- 2.GPU显存容量有限，无法将所有数据加载进去。显存溢出问题
    - 原因：因为输入是文件信息，比较大，如果直接输入所有数据，加上模型有些复杂度，如果不进行任何处理，显存是放不下多少数据的。
    - 解决方法：建一个csv表，两列，一个是文件的路径，一个是文件的标签用的keras中的fit_generator函数，写一个类似数据流处理的函数，每次获取一批需要训练数据的读取路径，然后根据路径来加载数据进行处理。
- 3.多机多GPU搭建，采用horovod+keras分布式架构
    - 这个相比于tensorflow自带的分布式tf.train.ClusterSpec具有以下几点优势：    
        - 1.并行效率高，采用Ring AllReduce通信原理，这个原理可以让每个主机只需要和它左右相连的机器进行通信进行数据交换，对于N各节点的GPU集群，整个下来的通讯次数为2*（N-1），有N-1步进行的是scatter reduce计算进行梯度融合，还有一个是步骤是Allgather，就是每部分的结果复制到下一个节点，同样需要通讯2*（N-1）次。就是假设一个GPU上计算的参数总量为K，则我们将其分为N份，每次我们向下传递K/N的数据量，并接受K/N的数据量。则总的数据传输量为2（N-1）*K/N，可以看到这个值是无限接近于2*K的，所以当增加GPU数量时，整个计算过程的数据传输量基本恒定。总传输量恒定意味着通信成本不随 GPU 数量增长而增长，也就是说我们系统拥有理论上的线性加速能力。     而之前的分布式都是会有一个参数服务器，一个分布式里有计算服务器和参数服务器两个角色，计算服务器负责计算，而参数服务器负责保存每步的计算结果，这个参数的保存方式也有两种，即同步和异步，同步的话，速度方面取决于最慢的服务器，但是计算效果较好，而异步的话速度快，但是结果会出现震荡，目前一般采用同步的方式。    
        - 2.另一个优点是，代码改动少。      
        - 3.支持的深度学习框架多，目前支持主流的tensorflow、keras、pytorch、MXNet框架。
- 4.多机多GPU分布式计算框架搭建     
    - 搭建的话需要先安装openmpi和NCCL，openmpi为通用通信接口的.需要和horovod社区进行沟通和交流解决相关问题。
- 5.存储问题
    - 单机存放不了所有的样本，采用NFS, nfs是网络文件系统，允许一个节点通过网络访问远程计算机的文件系统，远程文件系统可以被直接挂载到本地，文件操作和本地没有区别，如果是局域网的nfs那么io的性能也可以保证。后来因为每个机器读取样本速度不一，导致训练时间差，改用HDFS存放。
- 6.网络带宽问题
   - 网络带宽不够会限制多机训练，需要加大带宽。另一个方法是，压缩传输参数，因为参数矩阵中存在大量的0，我们通过设置参数spare_to_dense来压缩传输参数数据。
- Ring AllReduce
- 多GPU效率问题
   - 原因：正常多机多GPU执行效率不高，例如tensorflow自带的tf.train.ClusterSpec， 使用主机的IP地址和端口号创建ClusterSpec，是易于出错，不切实际的。里面一般会定义两种机器，worker和ps，worker用于计算获取每轮训练结果，而ps为参数服务器用于保存训练结果。里面的参数有同步和异步两种更新方式。同步的速度取决于计算最慢的机器，而异步则会导致结果震荡。看论文的实验结果，当GPU增大到128个后，会损失一半的计算资源。
	* 异步更新通信效率高速度快，但往往收敛不佳，因为一些速度慢的节点总会提供过时、错误的梯度方向
	* 同步更新通信效率低，通常训练更慢，但训练收敛稳定，因为同步更新基本等同于单卡调大 batch size 训练
	* 在实际生产环境中，我们通常很看重模型效果和训练速度，但当鱼与熊掌不能兼得时，模型效果还是更重要一些的，为此牺牲一些训练速度也不是不可接受，所以同步更新基本是主流方法

- 目前GPU并行为数据并行，就是比如我有3张GPU卡，一次batch迭代，每张GPU上分配64个数据进行计算，则实际的迭代为数据为单张卡的三倍，即192个数据。 然后，它们将本地计算好的梯度（直接或间接）与其他所有设备进行通信。通过增加GPU数量我们就能增强计算能力。
- 解决办法：采用horovod进行分布式搭建，这个深度学习工具，吸取了Facebook“Training ImageNet In 1 Hour”和百度“Ring Allreduce”的优点。 Horovod 是 Uber 新近开源的高效分布式训练通信框架，Horovod 本身只负责节点间网络通信、梯度融合，在运行时需要绑定TensorFlow 做单机运算。 在ring-allreduce体系结构中，不存在参数服务器。 相反，在迭代中，每个工作设备读取mini-batch中属于自己的那一部分，计算其梯度，将梯度发送到环上的后继近邻节点，并从环上的上一个近邻节点接收梯度。对于具有N个worker的环，所有worker都需要收集到经过其他worker的N-1个梯度信息之后，才足够计算能够计算新模型的梯度。 Ring-allreduce针对带宽优化的，因为它确保了每个主机上可用的上行和下载网络带宽得到充分利用（这一点与参数服务器模型相反）。 Ring-allreduce还可以将深层神经网络中较低层的梯度计算与高层梯度的传输重叠，从而进一步减少训练时间。就是每个N节点与其他两个节点进行2*（N-1）次通信。
- 优点：
    - 1.带宽充分利用 
    -  2.并行效率高，每个节点只需要和左右两个节点通讯进行数据传输，
- 这么做有什么好处呢？
- 下面我们来定量的分析一下，每个 GPU 在Scatter Reduce 阶段，接收 N-1 次数据，N 是 GPU 数量；每个 GPU 在allgather 阶段，接收 N-1 次 数据；每个 GPU 每次发送 K/N 大小数据块，K 是总数据大小；所以，Data Transferred=2(N−1)*K/N =(2(N−1)/N)*K，随着 GPU 数量 N 增加，总传输量恒定！总传输量恒定意味着通信成本不随 GPU 数量增长而增长，也就是说我们系统拥有理论上的线性加速能力。模型使用1.将pe文件进行字节编码，即每八位为一个特征单位，一个PE文件我们设定20万个字节的长度，如果不足在后面补0，过长则截去。然后作为模型的输入。这个里面用到一个Embedding层对字节进行了编码预处理，之后用到两个一维卷积层，卷积核长度为32，卷积核为128个，步长为4，每个卷积层后都有一个relu激活层。然后是一个1维max_pool层，pool_size=4之后是三个卷积层，卷积核长度为16，卷积核个数为128，步长为8，每个卷积层后都有三个relu激活层。之后是一个AveragePooling层。最后就是四个全连接层，长度依次是192,128,96,48，每层后面也有relu激活函数，最后一层为输出层，激活函数为sigmoid，输出一个0-1的数值，如果数值大于0.5则为白，小于0.5则为黑。
- 模型结构：
```
def Malconv_3(max_len=200000):
    win_size = 32
    vocab_size = 256
    filters_num=128
    inp = Input((max_len,))
    #emb = ElmoEmbeddingLayer(vocab_size,8)(inp)
    emb = Embedding(vocab_size, 8)(inp)
    conv1 = Conv1D(kernel_size=(win_size), filters=filters_num, strides=4, padding='same', activation='relu')(emb)
    conv2 = Conv1D(kernel_size=(win_size), filters=filters_num, strides=4, padding='same', activation='relu')(conv1)
    max_pool = MaxPooling1D(pool_size=4)(conv2)  
    conv3 = Conv1D(kernel_size=16, filters=filters_num, strides=8, padding='same',activation='relu')(max_pool)
    conv4 = Conv1D(kernel_size=16, filters=filters_num, strides=8, padding='same',activation='relu')(conv3)
    conv5 = Conv1D(kernel_size=16, filters=filters_num, strides=8, padding='same',activation='relu')(conv4)
    pooling_layer = GlobalAveragePooling1D()(conv5)
    full_connect_1 = Dense(192,activation='relu')(pooling_layer)
    full_connect_2 = Dense(128,activation='relu')(full_connect_1)
    full_connect_3 = Dense(96,activation='relu')(full_connect_2)
    full_connect_4 = Dense(48,activation='relu')(full_connect_3)
    out = Dense(1, activation='sigmoid')(full_connect_4)

    return Model(inp, out)   
```
-  TensorFlow 框架本身已经支持分布式训练，为什么不直接使用呢？
    - 因为 TensorFlow的分布式框架是基于参数服务器的，这种结构容易造成网络堵塞，需要一些额外的技巧降低并发通信量；并且开源版 TensorFlow 的跨机通信是通过 gRPC + Protocol Buffers 实现的，这种方案的问题是，首先 gRPC 本身的效率就比较差，其次使用 Protocol Buffers 序列化就意味着节点间的所有交互必须经过内存，无法使用GPUDirect RDMA，限制了速度提升；
    - 即使抛开性能问题，编写TensorFlow 的分布式代码也是一件十分繁琐的工作，有过相关经验的同学应该有所体会。Scatter Reduce为了方便说明，我们用梯度加和代替梯度融合。

- horovod 镜像
    - [注意删除旧的cuda镜像](https://github.com/horovod/horovod/issues/1353)
    ```
    mkdir horovod-docker
    wget -O horovod-docker/Dockerfile https://raw.githubusercontent.com/horovod/horovod/master/Dockerfile
    docker build -t horovod:latest horovod-docker
    ```

- horovod timeline使用
    - 分析性能瓶颈


### 千万级训练记录（supervisor调起mpirun）
```
nohup mpirun -np 2 -H 10.91.42.19:2 -bind-to none -map-by slot -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -mca pml ob1 -mca btl ^openib python /home/yanghang/temp_code/malconv-keras/src/train.py /home/yanghang/temp_code/malconv-keras/train_csv/data_test.csv --model_type=3 --batch_size=64 --max_len=200000 > train_data_test_log &
```

- supervisorctl监管：
```
sudo supervisord -c /etc/supervisord.conf

sudo vim /usr/local/share/supervisor/malconv.conf

tail -f /var/log/supervisor/malconv.log
```

- malconv.conf配置内容：
```
[program:malconv]
environment=LD_LIBRARY_PATH="/usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64:/home/yanghang/openmpi-4.0.0/lib",PATH="/home/yanghang/anaconda3/bin:/usr/local/cuda-9.0/bin:/usr/local/sbin:/sbin:/bin:/usr/sbin:/usr/bin:/home/s/bin:/usr/local/bin:/root/bin:/home/s/bin:/usr/local/bin:/home/yanghang/openmpi-4.0.0/bin"
command=/usr/local/bin/mpirun -np 2 -H 10.91.42.19:2 -bind-to none -map-by slot -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -mca pml ob1 -mca btl ^openib python /home/yanghang/temp_code/malconv-keras/src/train_by_dataset.py --batch_size=64 --max_len=200000
user=yanghang
autostart=true
autorestart=true
startsecs=3
redirect_stderr=true
stdout_logfile_maxbytes = 50MB
stdout_logfile_backups = 20
stdout_logfile = /var/log/supervisor/malconv.log
``` 

### horovod + keras搭建分布式计算集群

- 官网安装：
    - https://github.com/uber/horovod

- 安装如果遇到问题查相关手册：
    - https://github.com/uber/horovod/blob/master/docs/troubleshooting.md

- 1.install Open  MPI 
（要装4.0.0，其中装3.1.3是会遇到挂起问题的）
- 1.1 download:
    - 进入网页选择下载版本： https://www.open-mpi.org/software/ompi/v4.0/

    - If you have obtained a developer's checkout from Git, skip this FAQ question and consult these directions.
For everyone else, in general, all you need to do is expand the tarball, run the provided configure script, and then run "make all install". For example:
- 1.2 install openmpi(可以在openmpi官网查看安装教程):
```
 shell$ gunzip  -c openmpi-4.0.0.tar.gz | tar xf -
 shell$ cd openmpi-4.0.0
 shell$ ./configure --prefix=/usr/local   <...lots of output...>
 shell$  make all install
```
- 1.3 配置openmpi：
    - 执行：
        - sudo vim ~/.bashrc
    - 输入（根据自己安装的openmpi路径进行配置）：
    ```
    export PATH=$PATH:/home/yanghang/openmpi-4.0.0/bin   
    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/yanghang/openmpi-4.0.0/lib
    或者
    export PATH=$PATH:/usr/local/bin   
    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib
    ```
    - 执行：
        - source ~/.bashrc

- 1.4 test for mpirun：
```
cd examples
make
mpirun -np 2 hello_c
输出：
Hello, world, I am 0 of 2, (Open MPI v3.1.3, package: Open MPI yanghang@ml2.dev.zho.360es.cn Distribution, ident: 4.0.0, repo rev: v3.1.3, Oct 29, 2018, 124)
Hello, world, I am 1 of 2, (Open MPI v3.1.3, package: Open MPI yanghang@ml2.dev.zho.360es.cn Distribution, ident: 4.0.0, repo rev: v3.1.3, Oct 29, 2018, 124)
```

- 2.nccl安装
- 参考官网介绍进行安装：https://github.com/NVIDIA/nccl
    - 2.1 下载安装
    ```
    $ git clone https://github.com/NVIDIA/nccl.git
    $ cd nccl
    $ sudo make install -j4
    $ make -j src.build
    $ make src.build CUDA_HOME=/usr/local/cuda
    $ # Install tools to create rpm packages
    $ sudo yum install rpm-build rpmdevtools
    $ # Build NCCL rpm package
    $ make pkg.redhat.build
    $ ls build/pkg/rpm/
    ```
    - 2.2 配置nccl：
    - 执行：
       - $sudo vim ~/.bashrc 
    - 加入：
    - export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/yanghang/nccl/build/lib:/home/yanghang/nccl:/home/yanghang/nccl/build/include

- test for nccl:
```
$ git clone https://github.com/NVIDIA/nccl-tests.git
$ cd nccl-tests
$ make
$ ./build/all_reduce_perf -b 8 -e 256M -f 2 -g <ngpus>
```

- 3.horovod安装：
    - 安装命令：HOROVOD_NCCL_HOME=/home/yanghang/nccl/build HOROVOD_GPU_ALLREDUCE=NCCL pip install --no-cache-dir horovod 
    上面这条命令安装才能正常使用多GPU.
    - 使用pip install horovod这条命令安装可能会出现，有的使用CPU，有的使用GPU的错误。